{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "from load_dataset_title import get_dataset\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import FastText as ft\n",
    "\n",
    "from keras import layers, models, optimizers\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D,MaxPooling1D,Dropout,GlobalMaxPool1D,SpatialDropout1D,AveragePooling1D,GlobalAveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import regex as re\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import random as random\n",
    "\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python 3.6.4\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\python 3.6.4\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "##Load the word embeddings\n",
    "\n",
    "embed_model2 = ft.load_fasttext_format(\"cc.en.300.bin\")\n",
    "\n",
    "vec_dim = len(embed_model2[\"cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard thing to do for NLP tasks, apparently.\n",
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading large document\n",
      "19539 data entries loaded\n",
      "Neither undersampling nor oversampling specified\n",
      "No. of training examples: 15630\n",
      "No. of testing examples: 3908\n"
     ]
    }
   ],
   "source": [
    "#df_size = \"large\" is to load the large dataset, \"small\" is to load the small dataset.\n",
    "\n",
    "# sampling_method = \"oversample\"\n",
    "# sampling_method = \"undersample\"\n",
    "sampling_method = \"none\"\n",
    "\n",
    "def get_train_and_test(df_size = \"large\", sampling_method = None, percentage = 0.2):\n",
    "    def generate_balanced_dataset_undersampling(df): #nested helper function to generate balanced datasets\n",
    "        only_nonclickbait = df.loc[df['label'] == \"0\"]\n",
    "        only_clickbait = df.loc[df['label'] == \"1\"]\n",
    "\n",
    "        while len(only_nonclickbait)!= len(only_clickbait):\n",
    "            to_drop = random.randint(0, len(only_nonclickbait) - 1)\n",
    "            only_nonclickbait = only_nonclickbait.drop(only_nonclickbait.index[to_drop])\n",
    "\n",
    "        frames = [only_clickbait, only_nonclickbait]\n",
    "        final_balanced_dataset = pd.concat(frames)\n",
    "        print(\"Done generating balanced dataset via undersampling\")\n",
    "        return final_balanced_dataset\n",
    "\n",
    "    df = get_dataset(size = df_size) #use small for small dataset, large for large dataset. Will print the number of articles loaded.\n",
    "    \n",
    "    if sampling_method == \"oversample\":\n",
    "        X = df[\"title\"].apply(preprocess_text)\n",
    "        y = df['label'].astype(int)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = percentage, random_state = 51)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = percentage, random_state = 51)\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X_train_resized = X_train.reshape(-1,1)\n",
    "        X_train, y_train = ros.fit_resample(X_train_resized, y_train)\n",
    "        X_train = X_train.flatten()\n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    elif sampling_method == \"undersample\":\n",
    "        df_balanced = generate_balanced_dataset_undersampling(df)\n",
    "        df_balanced = df_balanced.sample(frac=1)\n",
    "        X = df_balanced[\"title\"].apply(preprocess_text)\n",
    "        y = df_balanced['label'].astype(int)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = percentage, random_state=51)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        print(\"Neither undersampling nor oversampling specified\")\n",
    "        X = df[\"title\"].apply(preprocess_text)\n",
    "        y = df['label'].astype(int)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = percentage, random_state=51)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "if sampling_method == \"oversample\":\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = get_train_and_test(df_size = \"large\", sampling_method = sampling_method)\n",
    "    pass\n",
    "elif sampling_method == \"undersample\":\n",
    "    X_train, X_test, y_train, y_test = get_train_and_test(df_size = \"large\", sampling_method = \"undersample\")\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = get_train_and_test(df_size = \"large\", sampling_method = \"None\")\n",
    "    pass\n",
    "\n",
    "print(\"No. of training examples:\", len(X_train))\n",
    "print(\"No. of testing examples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of title is: 219\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this cell is to pre-process the article titles by:\n",
    "1. Tokenizing\n",
    "2. Encoding a vector of words as a vector of numbers\n",
    "3. Post-padding it with zeros\n",
    "The length of all the article titles is set to the length of the longest title.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_max_length():\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(X_train)\n",
    "    encoded_X = t.texts_to_sequences(X_train)\n",
    "    max_length = 0\n",
    "    for i in encoded_X:\n",
    "        max_length = max(len(i), max_length)\n",
    "    return max_length + 1\n",
    "\n",
    "input_length = get_max_length()\n",
    "print(\"Max length of title is:\", input_length)\n",
    "\n",
    "def pre_process_input(array):\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(array)\n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    encoded_X = t.texts_to_sequences(array)\n",
    "\n",
    "    ##input_length is a global variable\n",
    "    padded_X = pad_sequences(encoded_X, maxlen = input_length,\n",
    "                          padding = \"post\")\n",
    "    \n",
    "    return (padded_X, t)\n",
    "\n",
    "#Create the padded X_test data as well as the padded X_train data\n",
    "padded_X_train, t_train = pre_process_input(X_train)\n",
    "vocab_size = len(t_train.word_index) + 1\n",
    "input_length = len(padded_X_train[0])\n",
    "padded_X_test = pre_process_input(X_test)[0]\n",
    "if sampling_method == \"oversample\":\n",
    "    padded_X_val = pre_process_input(X_val)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python 3.6.4\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Create the embedding matrix using the training data,\n",
    "embedding_matrix = np.zeros((vocab_size, vec_dim))\n",
    "for word,i in t_train.word_index.items():\n",
    "    embedding_vector = embed_model2[word]\n",
    "    embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: 1-D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 219, 300)          4024800   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 219, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 219, 16)           14416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 109, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 109, 14)           686       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 54, 14)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 54, 12)            516       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 4,040,431\n",
      "Trainable params: 15,631\n",
      "Non-trainable params: 4,024,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 6093 samples, validate on 1524 samples\n",
      "Epoch 1/100\n",
      "6093/6093 [==============================] - 5s 787us/step - loss: 0.6868 - accuracy: 0.5406 - val_loss: 0.6671 - val_accuracy: 0.6181\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66708, saving model to C:\\Users\\Admin\\Desktop\\CS3244Project\\CNN_Final/model_weights_undersampling.01-0.667.hdf5\n",
      "Epoch 2/100\n",
      "6093/6093 [==============================] - 4s 734us/step - loss: 0.6524 - accuracy: 0.6248 - val_loss: 0.6307 - val_accuracy: 0.6621\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66708 to 0.63067, saving model to C:\\Users\\Admin\\Desktop\\CS3244Project\\CNN_Final/model_weights_undersampling.02-0.631.hdf5\n",
      "Epoch 3/100\n",
      "6093/6093 [==============================] - 5s 762us/step - loss: 0.6234 - accuracy: 0.6670 - val_loss: 0.6192 - val_accuracy: 0.6811\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63067 to 0.61918, saving model to C:\\Users\\Admin\\Desktop\\CS3244Project\\CNN_Final/model_weights_undersampling.03-0.619.hdf5\n",
      "Epoch 4/100\n",
      "6093/6093 [==============================] - 5s 772us/step - loss: 0.6101 - accuracy: 0.6872 - val_loss: 0.6098 - val_accuracy: 0.6804\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61918 to 0.60983, saving model to C:\\Users\\Admin\\Desktop\\CS3244Project\\CNN_Final/model_weights_undersampling.04-0.610.hdf5\n",
      "Epoch 5/100\n",
      "6093/6093 [==============================] - 5s 768us/step - loss: 0.6002 - accuracy: 0.6923 - val_loss: 0.6118 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.60983\n",
      "Epoch 6/100\n",
      "6093/6093 [==============================] - 5s 766us/step - loss: 0.5910 - accuracy: 0.6992 - val_loss: 0.6070 - val_accuracy: 0.6877\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.60983 to 0.60695, saving model to C:\\Users\\Admin\\Desktop\\CS3244Project\\CNN_Final/model_weights_undersampling.06-0.607.hdf5\n",
      "Epoch 7/100\n",
      "6093/6093 [==============================] - 5s 764us/step - loss: 0.5790 - accuracy: 0.7087 - val_loss: 0.6035 - val_accuracy: 0.6844\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60695 to 0.60349, saving model to C:\\Users\\Admin\\Desktop\\CS3244Project\\CNN_Final/model_weights_undersampling.07-0.603.hdf5\n",
      "Epoch 8/100\n",
      "6093/6093 [==============================] - 5s 772us/step - loss: 0.5748 - accuracy: 0.7105 - val_loss: 0.6058 - val_accuracy: 0.6831\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.60349\n",
      "Epoch 9/100\n",
      "6093/6093 [==============================] - 5s 766us/step - loss: 0.5557 - accuracy: 0.7287 - val_loss: 0.5999 - val_accuracy: 0.6870\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.60349 to 0.59992, saving model to C:\\Users\\Admin\\Desktop\\CS3244Project\\CNN_Final/model_weights_undersampling.09-0.600.hdf5\n",
      "Epoch 10/100\n",
      "6093/6093 [==============================] - 5s 772us/step - loss: 0.5418 - accuracy: 0.7415 - val_loss: 0.6064 - val_accuracy: 0.6739\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.59992\n",
      "Epoch 11/100\n",
      "6093/6093 [==============================] - 5s 768us/step - loss: 0.5434 - accuracy: 0.7328 - val_loss: 0.6028 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.59992\n",
      "Epoch 12/100\n",
      "6093/6093 [==============================] - 5s 796us/step - loss: 0.5309 - accuracy: 0.7497 - val_loss: 0.6149 - val_accuracy: 0.6791\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.59992\n",
      "Epoch 13/100\n",
      "6093/6093 [==============================] - 5s 786us/step - loss: 0.5222 - accuracy: 0.7527 - val_loss: 0.6211 - val_accuracy: 0.6785\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.59992\n",
      "Model training complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the model\n",
    "\"\"\"\n",
    "#Hyper-Params\n",
    "epochs = 100 #50 orig\n",
    "batch_size = 32 #for stochastic gradient descent\n",
    "drop_embed = 0.3 #0.2 orig\n",
    "\n",
    "n_dense = 100\n",
    "dropout = 0.5 #0.5 orig\n",
    "\n",
    "n_conv_layer1 = 16\n",
    "n_conv_layer2 = 14\n",
    "n_conv_layer3 = 12\n",
    "n_conv_layer4 = 10\n",
    "k_conv = 3\n",
    "\n",
    "#Define model\n",
    "\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, vec_dim, weights = [embedding_matrix],\n",
    "              input_length = input_length, trainable = False)\n",
    "model.add(e)\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Conv1D(filters = n_conv_layer1, kernel_size = k_conv, activation = \"relu\", padding = \"same\"))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters = n_conv_layer2, kernel_size = k_conv, activation = \"relu\", padding = \"same\"))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters = n_conv_layer3, kernel_size = k_conv, activation = \"relu\", padding = \"same\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### summarize the model\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "### Create model checkpoints\n",
    "if sampling_method == \"oversample\":\n",
    "    ending_str = \"/model_weights_oversampling.{epoch:02d}-{val_loss:.3f}.hdf5\"\n",
    "elif sampling_method == \"undersample\":\n",
    "    ending_str = \"/model_weights_undersampling.{epoch:02d}-{val_loss:.3f}.hdf5\"\n",
    "else:\n",
    "    ending_str = \"/model_weights_imbalanced_training_data.{epoch:02d}-{val_loss:.3f}.hdf5\"\n",
    "\n",
    "output_dir = cwd\n",
    "modelcheckpoint = ModelCheckpoint(filepath = output_dir + ending_str,\n",
    "                                 monitor='val_loss', verbose=1, save_best_only=True)\n",
    "callbacks_list = [modelcheckpoint, EarlyStopping(monitor = \"val_loss\", patience = 4)]\n",
    "\n",
    "callbacks_list_no_chkpt = [EarlyStopping(monitor = \"val_loss\", patience = 2)]\n",
    "\n",
    "## fit the model\n",
    "if sampling_method == \"oversample\":\n",
    "    model.fit(padded_X_train, y_train, batch_size = batch_size, epochs=epochs, verbose=1, validation_data = (padded_X_val, y_val), callbacks = callbacks_list)\n",
    "else:\n",
    "    model.fit(padded_X_train, y_train, batch_size = batch_size, epochs=epochs, verbose=1, validation_split = 0.2, callbacks = callbacks_list)\n",
    "\n",
    "#fit with no checkpointing\n",
    "# if sampling_method == \"oversampling\":\n",
    "#     model.fit(padded_X_train, y_train, batch_size = batch_size, epochs=epochs, verbose=1, validation_data = (X_val, y_val), callbacks = callbacks_list_no_chkpt)\n",
    "# else:\n",
    "#     model.fit(padded_X_train, y_train, batch_size = batch_size, epochs=epochs, verbose=1, validation_split = 0.2, callbacks = callbacks_list_no_chkpt)\n",
    "\n",
    "\n",
    "print(\"Model training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "3908/3908 [==============================] - 1s 220us/step\n",
      "[0.5657322529547046, 0.7607471942901611]\n",
      "Confusion matrix for training data\n",
      "[[11413   375]\n",
      " [ 2530  1312]]\n",
      "Confusion matrix for testing data\n",
      "[[2921   68]\n",
      " [ 867   52]]\n",
      "Confusion matrix for test data:\n",
      "The F1 score is: 0.10009624639076034\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we evaluate the model to find the test loss and accuracy\n",
    "\"\"\"\n",
    "\n",
    "if sampling_method == \"oversample\":\n",
    "    model_loaded = load_model(\"model_weights_oversampling.03-0.670.hdf5\")\n",
    "elif sampling_method == \"undersample\": #somehow this leads to error...dunno why sia sian.\n",
    "    model_loaded = load_model(\"model_weights_undersampling.09-0.600.hdf5\")\n",
    "else:\n",
    "    model_loaded = load_model(\"model_weights_imbalanced_training_data.10-0.459.hdf5\")\n",
    "    \n",
    "print(model_loaded.metrics_names)\n",
    "print(model_loaded.evaluate(x=padded_X_test, y=y_test, verbose = 1))\n",
    "\n",
    "\"\"\"\n",
    "Here we print the confusion matrices for both training and test,\n",
    "and plot the confusion matrices for the test data.\n",
    "\n",
    "We also print the F1 score for the test data.\n",
    "\"\"\"\n",
    "def plot_cm_n_calculate_F1_score(confusion_matrix, normalise = True, fig_name = None):\n",
    "\n",
    "    TN = confusion_matrix[0][0]\n",
    "    TP = confusion_matrix[1][1]\n",
    "    FP = confusion_matrix[0][1]\n",
    "    FN = confusion_matrix[1][0]\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1_score = 2 * precision * recall / (precision + recall)\n",
    "    print(\"The F1 score is:\", F1_score)\n",
    "    \n",
    "    cm = [[0,0],[0,0]]\n",
    "    if normalise:\n",
    "        cm[0][0] = TN / (TN + FP)\n",
    "        cm[0][1] = FP / (TN + FP)\n",
    "        cm[1][0] = FN / (FN + TP)\n",
    "        cm[1][1] = TP / (FN + TP)\n",
    "        plt.title('Normalised Confusion matrix (1D CNN)', fontsize = 14)\n",
    "    else:\n",
    "        cm[0][0] = TN\n",
    "        cm[0][1] = FP\n",
    "        cm[1][0] = FN\n",
    "        cm[1][1] = TP\n",
    "        plt.title('Confusion matrix (1D CNN)', fontsize = 14)\n",
    "        \n",
    "    labels = ['Non-Clickbait', 'Clickbait']\n",
    "    df_cm = pd.DataFrame(cm, index = labels, columns = labels,)\n",
    "    sns_plot = sn.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, annot_kws={\"size\": 14})\n",
    "    fig = sns_plot.get_figure()\n",
    "    plt.xlabel('Predicted value', fontsize = 16)\n",
    "    plt.ylabel('True value', fontsize = 14)\n",
    "    plt.show()\n",
    "    \n",
    "    if fig_name:\n",
    "        fig.savefig(fig_name)\n",
    "        print(\"figure saved\")\n",
    "\n",
    "    \n",
    "#Printing confusion matrix for training data\n",
    "y_train_pred = model_loaded.predict(padded_X_train)\n",
    "y_train_pred = np.array([1 if i > 0.5 else 0 for i in y_train_pred])\n",
    "print(\"Confusion matrix for training data\")\n",
    "confusion_matrix_train = metrics.confusion_matrix(y_train, y_train_pred)\n",
    "print(confusion_matrix_train)\n",
    "\n",
    "#Printing confusion matrix for training data\n",
    "y_test_pred = model_loaded.predict(padded_X_test)\n",
    "y_test_pred = np.array([1 if i > 0.5 else 0 for i in y_test_pred])\n",
    "print(\"Confusion matrix for testing data\")\n",
    "confusion_matrix_test = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion_matrix_test)\n",
    "\n",
    "#Plotting the test data normalised confusion matrix\n",
    "print(\"Confusion matrix for test data:\")\n",
    "\n",
    "if sampling_method == \"oversample\":\n",
    "    plot_cm_n_calculate_F1_score(confusion_matrix_test, fig_name = \"Normalised_confusion_matrix_oversampling_test.png\")\n",
    "elif sampling_method == \"undersample\":\n",
    "    plot_cm_n_calculate_F1_score(confusion_matrix_test, fig_name = \"Normalised_confusion_matrix_undersampling_test.png\")\n",
    "else:\n",
    "    plot_cm_n_calculate_F1_score(confusion_matrix_test, fig_name = \"Normalised_confusion_matrix_inbalancedsampling_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
